{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from station_analysis import station_analysis, load_and_process_station_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"./data/tide_gauge_locations.csv\"\n",
    "locations = pd.read_csv(fn, index_col=\"uhslc_id\")\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hours_per_day = 20\n",
    "min_days_per_year = 320\n",
    "min_years_for_inclusion = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_fig_dir = \"./figures/quality_control/\"\n",
    "os.makedirs(qc_fig_dir, exist_ok=True)\n",
    "\n",
    "tide_prd_dir = \"./data/tide_predictions/\"\n",
    "os.makedirs(tide_prd_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uhid = 370\n",
    "tg = locations.loc[uhid]\n",
    "tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show QC'd version\n",
    "If QC instuctions already exist in ```quality_control.py```, then the following figure will include the QC adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsl, hsl_trnd, tide, quality_years = load_and_process_station_data(\n",
    "    tg,\n",
    "    min_hours_per_day,\n",
    "    min_days_per_year,\n",
    "    min_years_for_inclusion,\n",
    "    tide_prd_dir,\n",
    "    qc_fig_dir,\n",
    ")\n",
    "\n",
    "# detrended hourly values\n",
    "hsldt = hsl - hsl_trnd\n",
    "\n",
    "# calculate tidal residuals\n",
    "res = hsldt - tide\n",
    "\n",
    "# figure\n",
    "plt.figure()\n",
    "plt.plot(hsldt, label=\"detrended hourly\")\n",
    "# plt.plot(tide, label=\"predicted tide\")\n",
    "plt.plot(res, label=\"nontidal residuals\")\n",
    "plt.legend()\n",
    "plt.title(f\"{uhid:03d}: {tg.station_name} ({len(quality_years)} quality years)\")\n",
    "_ = plt.xticks(rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify station issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs_in_epoch = int(24 * 365.25 * 19)  # 19 years\n",
    "\n",
    "hsl = xr.load_dataset(f\"./data/tide_gauge_data/h{uhid:03d}.nc\")\n",
    "hsl = hsl.isel(record_id=0).sea_level.to_pandas()\n",
    "hsl.index = hsl.index.round(\"h\")\n",
    "hsl = hsl.loc[~hsl.index.duplicated(keep=\"first\")]\n",
    "hsl /= 10\n",
    "# hsl.loc[hsl < -50] = None\n",
    "\n",
    "Nt = hsl.size\n",
    "t_steps = [\"2014-02-01\", \"2015-10-20\", \"2016-07-01\", \"2017-09-01\"]\n",
    "step = pd.concat([pd.Series(0, index=hsl.index) for _ in t_steps], axis=1)\n",
    "for k, t in enumerate(t_steps):\n",
    "    step.loc[t:, k] = 1\n",
    "A = np.vstack([np.ones(Nt), np.arange(Nt), step.values.T]).T\n",
    "x = hsl.values\n",
    "z = ~np.isnan(x)\n",
    "c = np.linalg.lstsq(A[z, :], x[z], rcond=None)[0]\n",
    "y = pd.Series(A @ c, index=hsl.index)\n",
    "\n",
    "tide_prd_file = f\"{tide_prd_dir}t{uhid:03d}.csv\"\n",
    "tide = pd.read_csv(tide_prd_file, index_col=\"time\", parse_dates=True)[\"tide_prediction\"]\n",
    "tide -= tide.iloc[-hrs_in_epoch:].mean()\n",
    "\n",
    "condition = (hsl - tide).loc[\"2022-01-25\":\"2022-03\"] > 170\n",
    "drop = condition.loc[condition].index\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hsl, label=\"hourly sea leve\")\n",
    "# plt.plot(hsl.loc[drop], \".r\")\n",
    "# plt.plot(tide, label=\"predicted tide\")\n",
    "plt.plot(hsl - tide, label=\"nontidal residuals\")\n",
    "plt.plot((hsl - tide).loc[drop], \".r\")\n",
    "# plt.plot((hsl - tide).loc[hsl - tide > 180], \".r\", label=\"detrended hourly\")\n",
    "# plt.plot(y, \"r\", label=\"trend with step\")\n",
    "plt.legend()\n",
    "plt.title(f\"{uhid:03d}: {tg.station_name}\")\n",
    "_ = plt.xticks(rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(hsl.loc[drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hsl - tide)\n",
    "plt.plot((hsl - tide).groupby(pd.Grouper(freq=\"A\")).apply(lambda x: x.dropna().var()))\n",
    "_ = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun station analysis and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(f\"{tide_prd_dir}t{uhid:03d}.csv\")\n",
    "\n",
    "ga_file = \"./output/global_analysis.csv\"\n",
    "\n",
    "global_analysis = pd.read_csv(ga_file, index_col=0)\n",
    "global_analysis.index.name = \"uhid\"\n",
    "\n",
    "analysis = station_analysis(\n",
    "    tg,\n",
    "    min_hours_per_day,\n",
    "    min_days_per_year,\n",
    "    min_years_for_inclusion,\n",
    "    tide_prd_dir,\n",
    "    qc_fig_dir,\n",
    ")\n",
    "\n",
    "if analysis is not None:\n",
    "    global_analysis.loc[uhid, :] = analysis\n",
    "    global_analysis.to_csv(ga_file, index=True)\n",
    "    print(\"Analysis complete.\")\n",
    "else:\n",
    "    print(\"Analysis not performed, because global_analysis returned None.\")\n",
    "\n",
    "global_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
