{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "from geographic_sampling_ensemble import (\n",
    "    generate_random_spherical_points, \n",
    "    find_nearest_neighbors,\n",
    "    make_polygon_find_tg_inside,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load global analysis and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./output\"\n",
    "\n",
    "analysis = pd.read_csv(f\"{output_dir}/global_analysis.csv\")\n",
    "analysis = gpd.GeoDataFrame(\n",
    "    analysis, geometry=gpd.points_from_xy(analysis.lon, analysis.lat)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random geographic divisions on a sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some number of random areas\n",
    "np.random.seed(10)\n",
    "N_iterations = 1000\n",
    "random_areas = []\n",
    "# loop over number of iterations desired, but add a buffer since some will be malformed\n",
    "for _ in range(N_iterations + int(0.5 * N_iterations)):\n",
    "    # Find the path using nearest neighbor algorithm\n",
    "    working_on_it = True\n",
    "    while working_on_it:\n",
    "        # Generate random spherical points\n",
    "        num_vertices = 10\n",
    "        lat, lon = generate_random_spherical_points(num_vertices)\n",
    "        result = find_nearest_neighbors(lat, lon)\n",
    "        if result is not None:\n",
    "            plat, plon = result[0], result[1]\n",
    "            working_on_it = False\n",
    "    random_areas.append(dict(plat=plat, plon=plon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a figure showing examples of the random geographic divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = [3, 27, 54, 25]\n",
    "iterations2 = [None, None, 109, 200]\n",
    "\n",
    "fig = plt.figure(figsize=(9, 4.75))\n",
    "# colors = [\"#C9E7F8\", \"lightgray\", \"#D55E00\"]  # polygon, tg outside, tg inside\n",
    "# colors2 = [\"#F9F4B4\", \"lightgray\", \"#008F69\"]  # polygon, tg outside, tg inside\n",
    "\n",
    "for n, (i, i2) in enumerate(zip(iterations, iterations2)):\n",
    "\n",
    "    axis = fig.add_subplot(2, 2, n + 1, projection=ccrs.Mollweide())\n",
    "    axis.coastlines(zorder=-10, lw=0.5)\n",
    "    # axis.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor=\"lightgray\", zorder=-10)\n",
    "\n",
    "    labels = [\"Decagon 1\", None, \"TG Group 1\"] if n == 3 else None\n",
    "    labels2 = [\"Decagon 2\", \"Excluded\", \"TG Group 2\"] if n == 3 else None\n",
    "\n",
    "    if i2 is not None:\n",
    "        colors = [\"#C9E7F8\", \"darkgray\", \"#D55E00\"]  # polygon, tg outside, tg inside\n",
    "        colors2 = [\"#F9F4B4\", \"lightgray\", \"#008F69\"]  # polygon, tg outside, tg inside\n",
    "    else:\n",
    "        colors = [\"#C9E7F8\", \"#008F69\", \"#D55E00\"]  # polygon, tg outside, tg inside\n",
    "\n",
    "    plon, plat = random_areas[i][\"plon\"].copy(), random_areas[i][\"plat\"].copy()\n",
    "    make_polygon_find_tg_inside(axis, plon, plat, analysis, colors, labels=labels)\n",
    "\n",
    "    if i2 is not None:\n",
    "        plon, plat = random_areas[i2][\"plon\"].copy(), random_areas[i2][\"plat\"].copy()\n",
    "        make_polygon_find_tg_inside(\n",
    "            axis, plon, plat, analysis, colors2, zshift=-1, labels=labels2\n",
    "        )\n",
    "\n",
    "    # configure plot\n",
    "    axis.gridlines(linestyle=\":\")\n",
    "    axis.set_global()\n",
    "\n",
    "    # subplot labels\n",
    "    sp_labels = [\"a\", \"\", \"b\", \"\"]\n",
    "    axis.annotate(\n",
    "        text=sp_labels[n],\n",
    "        xy=(0.02, 0.93),\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "handles, labels = axis.get_legend_handles_labels()\n",
    "leg_order = [0, 2, 1, 3, 4]\n",
    "handles = [handles[i] for i in leg_order]\n",
    "labels = [labels[i] for i in leg_order]\n",
    "leg = fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    ncols=1,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.5, 0.49),\n",
    "    frameon=False,\n",
    "    fontsize=9,\n",
    ")\n",
    "\n",
    "# fig.suptitle(\"Examples of random geographic sampling\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/random_geographic_sampling.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/random_geographic_sampling.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of differences between large geographic regions/groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum number of tide gauges in the regions for the iteration to count\n",
    "min_group_tgs = 20\n",
    "\n",
    "# don't try to calculate median differences on columns that are not numeric\n",
    "data_columns = [\n",
    "    c\n",
    "    for c in analysis.columns\n",
    "    if (analysis[c].dtype == \"float64\") and c not in [\"lat\", \"lon\"]\n",
    "]\n",
    "analysis_data = analysis.loc[:, data_columns]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(111, projection=ccrs.Mollweide())\n",
    "\n",
    "io_median_diff_ensemble = []\n",
    "io_mean_diff_ensemble = []\n",
    "io_exclusion_median_diff_ensemble = []\n",
    "io_exclusion_mean_diff_ensemble = []\n",
    "iter = list(range(len(random_areas)))\n",
    "iter2 = iter.copy()\n",
    "random.shuffle(iter2)\n",
    "for i, i2 in zip(iter, iter2):\n",
    "\n",
    "    # get tg locations inside the random area\n",
    "    # sometimes (albeit rarely) polygons are malformed, which will cause an error; use\n",
    "    # try/except to skip these malformed polygons\n",
    "    plon, plat = random_areas[i][\"plon\"].copy(), random_areas[i][\"plat\"].copy()\n",
    "    try:\n",
    "        tg_in = make_polygon_find_tg_inside(\n",
    "            axis, plon, plat, analysis, show_polygon=False\n",
    "        )\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # check to be sure there are some minimum number of tgs in each group\n",
    "    if (tg_in.sum() < min_group_tgs) or ((~tg_in).sum() < min_group_tgs):\n",
    "        continue\n",
    "\n",
    "    # get absolute differences between medians inside and outside the random area\n",
    "    io_median_diff_ensemble.append(\n",
    "        (\n",
    "            analysis_data.loc[tg_in].median(axis=0)\n",
    "            - analysis_data.loc[~tg_in].median(axis=0)\n",
    "        ).abs()\n",
    "    )\n",
    "\n",
    "    # get absolute differences between means inside and outside the random area\n",
    "    io_mean_diff_ensemble.append(\n",
    "        (\n",
    "            analysis_data.loc[tg_in].mean(axis=0)\n",
    "            - analysis_data.loc[~tg_in].mean(axis=0)\n",
    "        ).abs()\n",
    "    )\n",
    "\n",
    "    # get tg locations outside the first random area and inside a second random area\n",
    "    plon, plat = random_areas[i2][\"plon\"].copy(), random_areas[i2][\"plat\"].copy()\n",
    "    try:\n",
    "        tg_in2 = make_polygon_find_tg_inside(\n",
    "            axis, plon, plat, analysis, show_polygon=False\n",
    "        )\n",
    "        tg_in2 = tg_in2 & ~tg_in\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # check to be sure there are some minimum number of tgs in each group\n",
    "    if (tg_in.sum() < min_group_tgs) or ((tg_in2).sum() < min_group_tgs):\n",
    "        continue\n",
    "\n",
    "    # get absolute differences between medians inside and outside with random exclusions\n",
    "    io_exclusion_median_diff_ensemble.append(\n",
    "        (\n",
    "            analysis_data.loc[tg_in].median(axis=0)\n",
    "            - analysis_data.loc[tg_in2].median(axis=0)\n",
    "        ).abs()\n",
    "    )\n",
    "\n",
    "    # get absolute differences between means inside and outside with random exclusions\n",
    "    io_exclusion_mean_diff_ensemble.append(\n",
    "        (\n",
    "            analysis_data.loc[tg_in].mean(axis=0)\n",
    "            - analysis_data.loc[tg_in2].mean(axis=0)\n",
    "        ).abs()\n",
    "    )\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# make dataframe of differences across iterations\n",
    "io_median_diff_ensemble = pd.DataFrame(io_median_diff_ensemble).iloc[:N_iterations]\n",
    "io_median_diff_ensemble.to_csv(\n",
    "    f\"{output_dir}/group_median_differences_ensemble.csv\", index=False\n",
    ")\n",
    "\n",
    "# make dataframe of differences across iterations\n",
    "io_mean_diff_ensemble = pd.DataFrame(io_mean_diff_ensemble).iloc[:N_iterations]\n",
    "io_mean_diff_ensemble.to_csv(\n",
    "    f\"{output_dir}/group_mean_differences_ensemble.csv\", index=False\n",
    ")\n",
    "\n",
    "# make dataframe of differences across iterations\n",
    "io_exclusion_median_diff_ensemble = pd.DataFrame(\n",
    "    io_exclusion_median_diff_ensemble\n",
    ").iloc[:N_iterations]\n",
    "io_exclusion_median_diff_ensemble.to_csv(\n",
    "    f\"{output_dir}/group_exclusion_median_differences_ensemble.csv\", index=False\n",
    ")\n",
    "\n",
    "# make dataframe of differences across iterations\n",
    "io_exclusion_mean_diff_ensemble = pd.DataFrame(io_exclusion_mean_diff_ensemble).iloc[\n",
    "    :N_iterations\n",
    "]\n",
    "io_exclusion_mean_diff_ensemble.to_csv(\n",
    "    f\"{output_dir}/group_exclusion_mean_differences_ensemble.csv\", index=False\n",
    ")\n",
    "\n",
    "# get percentiles across the ensemble\n",
    "percentiles = [80, 90, 95, 99]\n",
    "\n",
    "io_median_diff_percentiles = pd.DataFrame(\n",
    "    [io_median_diff_ensemble.quantile(p / 100, axis=0) for p in percentiles],\n",
    "    index=percentiles,\n",
    ").T\n",
    "io_median_diff_percentiles.to_csv(\n",
    "    f\"{output_dir}/group_median_differences_percentiles.csv\"\n",
    ")\n",
    "\n",
    "io_mean_diff_percentiles = pd.DataFrame(\n",
    "    [io_mean_diff_ensemble.quantile(p / 100, axis=0) for p in percentiles],\n",
    "    index=percentiles,\n",
    ").T\n",
    "io_median_diff_percentiles.to_csv(\n",
    "    f\"{output_dir}/group_mean_differences_percentiles.csv\"\n",
    ")\n",
    "\n",
    "io_exclusion_median_diff_percentiles = pd.DataFrame(\n",
    "    [io_exclusion_median_diff_ensemble.quantile(p / 100, axis=0) for p in percentiles],\n",
    "    index=percentiles,\n",
    ").T\n",
    "io_exclusion_median_diff_percentiles.to_csv(\n",
    "    f\"{output_dir}/group_exclusion_median_differences_percentiles.csv\"\n",
    ")\n",
    "\n",
    "io_exclusion_mean_diff_percentiles = pd.DataFrame(\n",
    "    [io_exclusion_mean_diff_ensemble.quantile(p / 100, axis=0) for p in percentiles],\n",
    "    index=percentiles,\n",
    ").T\n",
    "io_exclusion_median_diff_percentiles.to_csv(\n",
    "    f\"{output_dir}/group_exclusion_mean_differences_percentiles.csv\"\n",
    ")\n",
    "\n",
    "io_median_diff_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_exclusion_median_diff_ensemble.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
