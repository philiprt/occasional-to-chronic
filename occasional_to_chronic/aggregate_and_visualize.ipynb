{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c77083-a3fe-4525-ad31-5d37becff730",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "# there are various runtime warnings generated by the presence of infinite dt values\n",
    "# in the analysis. this is not a bug. ignore these warnings ...\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import t\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "\n",
    "from station_analysis import load_and_process_station_data\n",
    "from aggregate_and_visualize import (\n",
    "    dt_table,\n",
    "    o2c_scatter_map,\n",
    "    o2c_scatter_plot,\n",
    "    hist_violin,\n",
    "    plot_change_with_slr,\n",
    "    MulticolorPatch,\n",
    "    MulticolorPatchHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901f8fb-fe4d-44ca-a76b-dd9395bd0b11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load global analysis and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81bd4c",
   "metadata": {},
   "source": [
    "First configure the quantities to use in the aggregations and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e91195",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_est_type = \"median\"  # mean or median\n",
    "chronic_freq = 26  # 20, 26, or 50 days per year\n",
    "scenario = \"Int\"  # Low, IntLow, Int, IntHigh, High\n",
    "significance_level = 95  # 80, 90, 95, or 99\n",
    "\n",
    "# colors = [\"#63b4d1\", \"#db3a34\", \"#ece4d5\", \"#BD93D8\"]\n",
    "# colors = [\"#63b4d1\", \"#710627\", \"#ece4d5\", \"#B6A1BA\"]\n",
    "# colors = [\"#63b4d1\", \"#db3a34\", \"#dedede\", \"#87C38F\"]\n",
    "colors = [\"#56B4E9\", \"#F3EA68\", \"#dddddd\", \"#CC79A7\", \"#E69F00\", \"#D55E00\", \"#009E73\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baedde3",
   "metadata": {},
   "source": [
    "Load the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdbbad-e1a8-48f9-ad9c-27ce9e2f8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./output\"\n",
    "\n",
    "analysis = pd.read_csv(f\"{output_dir}/global_analysis.csv\", index_col=0)\n",
    "analysis = gpd.GeoDataFrame(\n",
    "    analysis, geometry=gpd.points_from_xy(analysis.lon, analysis.lat)\n",
    ")\n",
    "\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c22a5a",
   "metadata": {},
   "source": [
    "## Load results of geographic sampling experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045de102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary global classifications\n",
    "\n",
    "io_median_diff_percentiles = pd.read_csv(\n",
    "    f\"{output_dir}/group_median_differences_percentiles.csv\", index_col=0\n",
    ")\n",
    "io_median_diff_percentiles.columns = [\n",
    "    int(c) for c in io_median_diff_percentiles.columns\n",
    "]\n",
    "io_median_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_median_differences_ensemble.csv\", index_col=0\n",
    ")\n",
    "\n",
    "io_mean_diff_percentiles = pd.read_csv(\n",
    "    f\"{output_dir}/group_mean_differences_percentiles.csv\", index_col=0\n",
    ")\n",
    "io_mean_diff_percentiles.columns = [int(c) for c in io_mean_diff_percentiles.columns]\n",
    "io_mean_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_mean_differences_ensemble.csv\", index_col=0\n",
    ")\n",
    "\n",
    "# for subsetted groups\n",
    "\n",
    "io_exclusion_median_diff_percentiles = pd.read_csv(\n",
    "    f\"{output_dir}/group_exclusion_median_differences_percentiles.csv\", index_col=0\n",
    ")\n",
    "io_exclusion_median_diff_percentiles.columns = [\n",
    "    int(c) for c in io_exclusion_median_diff_percentiles.columns\n",
    "]\n",
    "io_exclusion_median_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_exclusion_median_differences_ensemble.csv\", index_col=0\n",
    ")\n",
    "\n",
    "io_exclusion_mean_diff_percentiles = pd.read_csv(\n",
    "    f\"{output_dir}/group_exclusion_mean_differences_percentiles.csv\", index_col=0\n",
    ")\n",
    "io_exclusion_mean_diff_percentiles.columns = [\n",
    "    int(c) for c in io_exclusion_mean_diff_percentiles.columns\n",
    "]\n",
    "io_exclusion_mean_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_exclusion_mean_differences_ensemble.csv\", index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18364c8a",
   "metadata": {},
   "source": [
    "## Differences between geographic groups of TG locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e1bd8",
   "metadata": {},
   "source": [
    "### Define Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a34521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of island stations (also includes designation as colonized or not)\n",
    "islands = pd.read_csv(\"./data/islands.csv\")\n",
    "\n",
    "not_island_ids = [uid for uid in analysis.index if uid not in islands.uhid]\n",
    "not_island_df = analysis.loc[not_island_ids, [\"name\", \"country\", \"lon\", \"lat\"]]\n",
    "not_island_df.index.name = \"uhid\"\n",
    "not_island_df = not_island_df.sort_values(by=\"country\")\n",
    "not_island_df.to_csv(\"./data/not_islands.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"all\": analysis.hdi > -1000,\n",
    "    # global south and global north\n",
    "    \"globalN\": analysis.hdi >= 0.8,\n",
    "    \"globalS\": analysis.hdi < 0.8,\n",
    "    # low latitude (< 30) and high latitude (> 30)\n",
    "    \"highLat\": np.abs(analysis.lat) > 30,\n",
    "    \"lowLat\": np.abs(analysis.lat) <= 30,\n",
    "    # East and West Hemispheres\n",
    "    \"westHemi\": (analysis.lon < 30) | (analysis.lon >= 180),\n",
    "    \"eastHemi\": (analysis.lon >= 30) & (analysis.lon < 180),\n",
    "    # islands and continents\n",
    "    \"island\": analysis.index.isin(islands.uhid),\n",
    "    \"continent\": ~analysis.index.isin(islands.uhid),\n",
    "    \"colonized\": analysis.index.isin(islands.uhid.loc[islands.colonized]),\n",
    "}\n",
    "\n",
    "groups = {\n",
    "    **groups,\n",
    "    **{\n",
    "        # lat bands east and west\n",
    "        \"highLat_westHemi\": groups[\"highLat\"] & groups[\"westHemi\"],\n",
    "        \"highLat_eastHemi\": groups[\"highLat\"] & ~groups[\"westHemi\"],\n",
    "        \"lowLat_westHemi\": groups[\"lowLat\"] & groups[\"westHemi\"],\n",
    "        \"lowLat_eastHemi\": groups[\"lowLat\"] & ~groups[\"westHemi\"],\n",
    "        # islands in the global south\n",
    "        \"globalS_island\": groups[\"island\"] & groups[\"globalS\"],\n",
    "        \"globalS_continent\": groups[\"continent\"] & groups[\"globalS\"],\n",
    "        # global north high-latitude\n",
    "        \"globalN_highLat\": groups[\"globalN\"] & groups[\"highLat\"],\n",
    "        # global north colonized\n",
    "        \"globalN_colonized\": groups[\"globalN\"] & groups[\"colonized\"],\n",
    "        # global north excluding colonized (i.e., domestic)\n",
    "        \"globalN_domestic\": groups[\"globalN\"] & ~groups[\"colonized\"],\n",
    "        # continental in the global north\n",
    "        \"globalN_continent\": groups[\"globalN\"] & groups[\"continent\"],\n",
    "        # global north west hemisphere\n",
    "        \"globalN_westHemi\": groups[\"globalN\"] & groups[\"westHemi\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "groups = {\n",
    "    **groups,\n",
    "    **{\n",
    "        \"globalN_westHemi_continent\": groups[\"globalN_westHemi\"] & groups[\"continent\"],\n",
    "        \"globalN_westHemi_highLat\": groups[\"globalN_westHemi\"] & groups[\"highLat\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "groups = {\n",
    "    **groups,\n",
    "    **{\n",
    "        \"globalN_domestic_westHemi\": groups[\"globalN_domestic\"] & groups[\"westHemi\"],\n",
    "        \"globalN_domestic_highLat\": groups[\"globalN_domestic\"] & groups[\"highLat\"],\n",
    "        \"globalN_domestic_westHemi_highLat\": (\n",
    "            groups[\"globalN_domestic\"] & groups[\"highLat_westHemi\"]\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "groups = {\n",
    "    **groups,\n",
    "    **{\n",
    "        \"globalN_domestic_NAEU\": (\n",
    "            groups[\"globalN_domestic_westHemi\"] & (analysis.lat > 22)\n",
    "        ),\n",
    "        \"globalN_domestic_westHemiOther\": (\n",
    "            groups[\"globalN_domestic_westHemi\"] & (analysis.lat <= 22)\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# convert to numpy boolean to avoid issues with pandas indices\n",
    "groups = {\n",
    "    g: groups[g].values if type(groups[g]) is not np.ndarray else groups[g]\n",
    "    for g in groups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1485cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_ll_in_isl = (\n",
    "    100 * (groups[\"lowLat\"] & groups[\"island\"]).sum() / groups[\"island\"].sum()\n",
    ")\n",
    "pct_isl_in_ll = (\n",
    "    100 * (groups[\"lowLat\"] & groups[\"island\"]).sum() / groups[\"lowLat\"].sum()\n",
    ")\n",
    "print(f\"{pct_ll_in_isl:.1f}% of islands are low latitude\")\n",
    "print(f\"{pct_isl_in_ll:.1f}% of low latitude locations are islands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de234b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference in dt global medians between the two start years for the chosen central estimate, scenario, and chronic frequency\n",
    "dt_50 = analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2050\"].median()\n",
    "dt_20 = analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"].median()\n",
    "dt_diff = dt_20 - dt_50\n",
    "print(f\"dt beginning 2020: {dt_20:.2f} years\")\n",
    "print(f\"dt beginning 2050: {dt_50:.2f} years\")\n",
    "print(f\"dt difference (2020 minus 2050): {dt_diff:.2f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a couple of groups to the analysis dataframe for making manuscript table\n",
    "analysis[\"island\"] = groups[\"island\"]\n",
    "analysis[\"domestic\"] = ~groups[\"colonized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1032a1",
   "metadata": {},
   "source": [
    "### Explore groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5317e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    3,\n",
    "    1,\n",
    "    figsize=(6, 8),\n",
    "    subplot_kw=dict(projection=ccrs.Mollweide(central_longitude=210)),\n",
    ")\n",
    "\n",
    "# for n, g in enumerate([\"lowLat\", \"globalS\", \"island\"]):\n",
    "for n, g in enumerate([\"globalS\", \"globalN_colonized\", \"globalN_domestic_NAEU\"]):\n",
    "\n",
    "    ax[n].add_feature(cfeature.LAND.with_scale(\"110m\"), color=\"gray\")\n",
    "    ax[n].gridlines(linewidth=0.5, color=\"k\", linestyle=\":\")\n",
    "    co = ax[n].scatter(\n",
    "        x=analysis.lon,\n",
    "        y=analysis.lat,\n",
    "        c=colors[0],\n",
    "        edgecolors=\"k\",\n",
    "        linewidths=0.5,\n",
    "        s=50,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    co = ax[n].scatter(\n",
    "        x=analysis.lon.loc[groups[g]],\n",
    "        y=analysis.lat.loc[groups[g]],\n",
    "        c=colors[1],\n",
    "        edgecolors=\"k\",\n",
    "        linewidths=0.5,\n",
    "        s=50,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    ax[n].set_global()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa750aba",
   "metadata": {},
   "source": [
    "### Calculate median and other percentiles of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, a few global HDI statistics based on countries, not TGs\n",
    "national_values = {\n",
    "    \"Global South HDI\": np.median(\n",
    "        analysis.hdi.loc[groups[\"globalS\"]].dropna().unique()\n",
    "    ),\n",
    "    \"Domestic NA/EU HDI\": np.median(\n",
    "        analysis.hdi.loc[groups[\"globalN_domestic_NAEU\"]].dropna().unique()\n",
    "    ),\n",
    "    \"Domestic WH Not NA/EU HDI\": np.median(\n",
    "        analysis.hdi.loc[groups[\"globalN_domestic_westHemiOther\"]].dropna().unique()\n",
    "    ),\n",
    "}\n",
    "pd.Series(national_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate numeric columns in the analysis dataframe\n",
    "analysis_data = analysis[\n",
    "    [\n",
    "        c\n",
    "        for c in analysis.columns\n",
    "        if c\n",
    "        not in [\n",
    "            \"name\",\n",
    "            \"country\",\n",
    "            \"lat\",\n",
    "            \"lon\",\n",
    "            \"geometry\",\n",
    "            \"island\",\n",
    "            \"domestic\",\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "percentiles = [5, 17, 50, 83, 95]\n",
    "group_percentiles = pd.DataFrame(\n",
    "    index=[g for g in groups], columns=analysis_data.columns\n",
    ")\n",
    "for g in groups:\n",
    "    this_group_percentiles = pd.DataFrame(\n",
    "        [analysis_data.loc[groups[g]].quantile(p / 100, axis=0) for p in percentiles],\n",
    "        index=percentiles,\n",
    "    ).round(4)\n",
    "    group_percentiles.loc[g] = pd.Series(\n",
    "        {c: this_group_percentiles[c].to_list() for c in analysis_data.columns}\n",
    "    )\n",
    "group_counts = pd.Series({g: groups[g].sum() for g in groups})\n",
    "group_counts.name = \"N\"\n",
    "group_percentiles = pd.concat([group_counts, group_percentiles], axis=1)\n",
    "group_percentiles[\n",
    "    [\n",
    "        \"N\",\n",
    "        \"hdi\",\n",
    "        f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2050\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970cb33",
   "metadata": {},
   "source": [
    "### Calculate median group differences and probability that each could occur by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_{central_est_type}_differences_ensemble.csv\"\n",
    ")\n",
    "io_exclusion_diff_ensemble = pd.read_csv(\n",
    "    f\"{output_dir}/group_exclusion_{central_est_type}_differences_ensemble.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def prob_group_diff_occur_chance(group_1, group_2, data, diff_ensemble):\n",
    "    diff = (\n",
    "        (data.loc[group_2].median(axis=0) - data.loc[group_1].median(axis=0))\n",
    "        .abs()\n",
    "        .round(4)\n",
    "    )\n",
    "    prob = (diff_ensemble > diff).sum(axis=0) / diff_ensemble.index.size\n",
    "    return pd.Series(\n",
    "        [(d, p) for d, p in zip(diff.values, prob.values)], index=diff.index\n",
    "    )\n",
    "\n",
    "\n",
    "groups_to_compare = dict(\n",
    "    globalN_vs_globalS=[\"globalN\", \"globalS\"],\n",
    "    highLat_vs_lowLat=[\"highLat\", \"lowLat\"],\n",
    "    continent_vs_island=[\"continent\", \"island\"],\n",
    "    HLWH_vs_HLEH=[\"highLat_westHemi\", \"highLat_eastHemi\"],\n",
    "    LLWH_vs_LLEH=[\"lowLat_westHemi\", \"lowLat_eastHemi\"],\n",
    "    GS_vs_DGN=[\"globalS\", \"globalN_domestic\"],\n",
    "    GS_vs_DGN_WH=[\"globalS\", \"globalN_domestic_westHemi\"],\n",
    "    GS_vs_DGN_NAEU=[\"globalS\", \"globalN_domestic_NAEU\"],\n",
    "    # GS_vs_GNHL=[\"globalS\", \"globalN_highLat\"],\n",
    "    # GS_vs_GNWHHL=[\"globalS\", \"globalN_westHemi_highLat\"],\n",
    "    # GS_vs_GNWHCN=[\"globalS\", \"globalN_westHemi_continent\"],\n",
    ")\n",
    "all_gauge_comps = [\"globalN_vs_globalS\", \"highLat_vs_lowLat\", \"continent_vs_island\"]\n",
    "\n",
    "group_diff_with_prob_chance = pd.DataFrame(\n",
    "    [\n",
    "        prob_group_diff_occur_chance(\n",
    "            groups[groups_to_compare[gc][0]],\n",
    "            groups[groups_to_compare[gc][1]],\n",
    "            analysis_data,\n",
    "            io_diff_ensemble if gc in all_gauge_comps else io_exclusion_diff_ensemble,\n",
    "        )\n",
    "        for gc in groups_to_compare\n",
    "    ],\n",
    "    index=[gc for gc in groups_to_compare],\n",
    ")\n",
    "group_diff_with_prob_chance[\n",
    "    [\n",
    "        f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2050\",\n",
    "        f\"res_dymx_std\",\n",
    "        f\"slr_total_{scenario}_2020_2050\",\n",
    "        f\"slr_ocean_dyn_{scenario}_2020_2050\",\n",
    "        f\"slr_massdef_{scenario}_2020_2050\",\n",
    "        f\"slr_vlm_{scenario}_2020_2050\",\n",
    "        f\"slr_ais_{scenario}_2020_2050\",\n",
    "        f\"slr_gis_{scenario}_2020_2050\",\n",
    "        f\"slr_glaciers_{scenario}_2020_2050\",\n",
    "        f\"slr_landwater_{scenario}_2020_2050\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb61fc",
   "metadata": {},
   "source": [
    "## Make station table for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dict(\n",
    "    uhid=(\"Station Metadata\", \"UH ID\"),\n",
    "    name=(\"Station Metadata\", \"Name\"),\n",
    "    country=(\"Station Metadata\", \"Country\"),\n",
    "    lon=(\"Station Metadata\", \"Longitude\"),\n",
    "    lat=(\"Station Metadata\", \"Latitude\"),\n",
    "    n_good_years=(\"Station Metadata\", \"Valid Years\"),\n",
    "    hdi=(\"Classifications\", \"HDI\"),\n",
    "    island=(\"Classifications\", \"Island\"),\n",
    "    domestic=(\"Classifications\", \"Domestic\"),\n",
    "    dh_median_26_days=(\"Transitions\", \"∆h (cm)\"),\n",
    "    dt_median_26_days_Int_2020=(\"Transitions\", \"∆t (years)\"),\n",
    "    res_hf_dymx_std=(\"Process Proxies (cm)\", \"Storminess\"),\n",
    "    res_momn_q75_std=(\"Process Proxies (cm)\", \"MSL Variability\"),\n",
    "    tide_dymx_std=(\"Process Proxies (cm)\", \"High-Tide Modulation\"),\n",
    "    slr_total_Int_2020_2050=(\"Relative SLR (cm)\", \"Total\"),\n",
    "    slr_ocean_dyn_Int_2020_2050=(\"Relative SLR (cm)\", \"Sterodynamic\"),\n",
    "    slr_massdef_Int_2020_2050=(\"Relative SLR (cm)\", \"Mass and Deformation\"),\n",
    "    slr_vlm_Int_2020_2050=(\"Relative SLR (cm)\", \"Vertical Land Motion\"),\n",
    ")\n",
    "station_table = analysis.loc[:, [c for c in columns][1:]]\n",
    "station_table = station_table.reset_index()\n",
    "station_table = station_table.sort_values(by=[\"country\", \"name\"])\n",
    "station_table.columns = pd.MultiIndex.from_tuples([columns[c] for c in columns])\n",
    "station_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2538c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\n",
    "    \"./output/supplementary_tables_unformatted.xlsx\", engine=\"xlsxwriter\"\n",
    ") as writer:\n",
    "    # Write the DataFrame to the Excel file\n",
    "    station_table.to_excel(writer, sheet_name=\"Stations\")\n",
    "\n",
    "    # Access the XlsxWriter workbook and worksheet objects\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[\"Stations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9a04c-8b03-4e8a-a9e9-c04ee770eff1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4f549",
   "metadata": {},
   "source": [
    "### $\\Delta h$ schematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [\n",
    "    # dict(uhid=57, figure_name=\"Honolulu, HI\"),\n",
    "    dict(uhid=5, figure_name=\"Majuro, MI\"),\n",
    "    dict(uhid=264, figure_name=\"Atlantic City, USA\"),\n",
    "]\n",
    "\n",
    "run_schematic_analysis = False\n",
    "\n",
    "schematic_locations_fn = \"./output/schematic_locations.csv\"\n",
    "if os.path.exists(schematic_locations_fn):\n",
    "    locations = pd.read_csv(\n",
    "        schematic_locations_fn,\n",
    "        dtype=dict(\n",
    "            station_country_code=int,\n",
    "            uhslc_id=int,\n",
    "        ),\n",
    "        index_col=\"uhslc_id\",\n",
    "    )\n",
    "else:\n",
    "    locations = None\n",
    "\n",
    "schematic_dymxdt_fn = \"./output/schematic_daily_max_dt.csv\"\n",
    "if os.path.exists(schematic_dymxdt_fn):\n",
    "    daily_max_dt = pd.read_csv(\n",
    "        schematic_dymxdt_fn,\n",
    "        index_col=\"time\",\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    daily_max_dt.columns = daily_max_dt.columns.astype(int)\n",
    "else:\n",
    "    daily_max_dt = None\n",
    "\n",
    "for uhid in [s[\"uhid\"] for s in stations]:\n",
    "    if locations is None or daily_max_dt is None:\n",
    "        run_schematic_analysis = True\n",
    "        break\n",
    "    if uhid not in locations.index or uhid not in daily_max_dt.columns:\n",
    "        run_schematic_analysis = True\n",
    "\n",
    "fn = \"./data/tide_gauge_locations.csv\"\n",
    "\n",
    "# if the schematic analysis already does not exist, do the analysis\n",
    "if run_schematic_analysis:\n",
    "\n",
    "    # load the metadata file if it already exists\n",
    "    locations = pd.read_csv(\n",
    "        fn,\n",
    "        dtype=dict(\n",
    "            station_country_code=int,\n",
    "            uhslc_id=int,\n",
    "        ),\n",
    "        index_col=\"uhslc_id\",\n",
    "    )\n",
    "\n",
    "    locations = locations.loc[[s[\"uhid\"] for s in stations]]\n",
    "    locations.station_name = [s[\"figure_name\"] for s in stations]\n",
    "    locations[[\"h01\", \"h26\"]] = None\n",
    "\n",
    "    min_hours_per_day = 20\n",
    "    min_days_per_year = 320\n",
    "    min_years_for_inclusion = 9\n",
    "\n",
    "    daily_max_dt = dict()\n",
    "\n",
    "    def get_detrended_tg_data(tg):\n",
    "        hsl, hsl_trnd, _, _ = load_and_process_station_data(\n",
    "            tg,\n",
    "            min_hours_per_day,\n",
    "            min_days_per_year,\n",
    "            min_years_for_inclusion,\n",
    "            tide_prd_dir=\"./data/tide_predictions/\",\n",
    "        )\n",
    "\n",
    "        # return detrended hourly values\n",
    "        return hsl - hsl_trnd\n",
    "\n",
    "    for uhid, tg in locations.iterrows():\n",
    "\n",
    "        hsldt = get_detrended_tg_data(tg)\n",
    "\n",
    "        # get daily max of detrended hourly values\n",
    "        dmxdt = hsldt.groupby(pd.Grouper(freq=\"D\")).apply(\n",
    "            lambda x: x.mean() if (x.dropna().count() > min_hours_per_day) else None\n",
    "        )\n",
    "\n",
    "        # calculate high and low\n",
    "        high = np.floor(np.max(dmxdt))\n",
    "        low = np.floor(0.5 * np.std(dmxdt))  # halfstd\n",
    "\n",
    "        # define range of thresholds\n",
    "        thresholds = np.arange(low, high + 0.1, 0.1)\n",
    "\n",
    "        # get number of daily max exceedances in each met year over each threshold\n",
    "        dmxdt_gy = dmxdt.groupby(dmxdt.index.year)\n",
    "        Nxpy = pd.concat(\n",
    "            [dmxdt_gy.apply(lambda x: (x > thrsh).sum()) for thrsh in thresholds],\n",
    "            axis=1,\n",
    "        )\n",
    "        Nxpy.columns = thresholds\n",
    "\n",
    "        # calculate the average number of daily max exceedances per met year for each threshold\n",
    "        Nxpy_mn = Nxpy.median(axis=0)\n",
    "\n",
    "        h01 = Nxpy_mn.loc[Nxpy_mn >= 1].idxmin()\n",
    "        h26 = Nxpy_mn.loc[Nxpy_mn >= 26].idxmin()\n",
    "\n",
    "        daily_max_dt[uhid] = dmxdt\n",
    "        locations.loc[uhid, \"h01\"] = h01\n",
    "        locations.loc[uhid, \"h26\"] = h26\n",
    "\n",
    "    daily_max_dt = pd.DataFrame(daily_max_dt)\n",
    "    daily_max_dt.to_csv(schematic_dymxdt_fn, index=True)\n",
    "\n",
    "    locations.to_csv(schematic_locations_fn, index=True)\n",
    "\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "x_offset = 11000\n",
    "y_offset = [0, -160]  # -145]\n",
    "dst_fact = [5e4, 10e4]\n",
    "name_offset = [-25, -25]\n",
    "scale_bottom = -275\n",
    "for n, (uhid, tg) in enumerate(locations.iterrows()):\n",
    "    dmxdt = daily_max_dt[uhid]\n",
    "    tg_name, h01, h26 = locations.loc[uhid][[\"station_name\", \"h01\", \"h26\"]].to_list()\n",
    "\n",
    "    dmxdt_rng = dmxdt.loc[\"1998.5\":\"2022.5\"].copy()\n",
    "    dmxdt_rng.index = range(dmxdt_rng.index.size)\n",
    "\n",
    "    dst_vals = dmxdt_rng.dropna().values\n",
    "    kde = gaussian_kde(dst_vals)\n",
    "    dst_x = np.linspace(min(dst_vals), max(dst_vals), 1000)\n",
    "    dst = pd.Series(kde(dst_x), index=dst_x)\n",
    "\n",
    "    plot_change_with_slr(\n",
    "        ax=ax1,\n",
    "        name=tg_name,\n",
    "        dymx=dmxdt_rng,\n",
    "        dst=dst,\n",
    "        dst_fact=dst_fact[n],\n",
    "        colors=[colors[n] for n in [0, 1, 0]],\n",
    "        offsets=[x_offset, y_offset[n]],\n",
    "        thrsh=h01,\n",
    "        slr=h01 - h26,\n",
    "        name_offset=name_offset[n],\n",
    "        scale_bottom=scale_bottom,\n",
    "        labels=True if n == 0 else False,\n",
    "    )\n",
    "\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_xlim([-4000, dmxdt_rng.index[-1] + x_offset + 4000])\n",
    "ax1.set_ylim([scale_bottom - 5, 50])\n",
    "\n",
    "plt.legend(\n",
    "    loc=\"lower right\", bbox_to_anchor=(0.92, -0.015), frameon=False, borderpad=0, ncol=2\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig1.savefig(\"./figures/manuscript/dh_schematic.png\", dpi=300)\n",
    "fig1.savefig(\"./figures/manuscript/dh_schematic.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0431f5",
   "metadata": {},
   "source": [
    "### Table of $\\Delta t$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14946ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_groups = dict(\n",
    "    all=\"Global\",\n",
    "    lowLat=\"Low Latitude\",\n",
    "    highLat=\"High Latitude\",\n",
    "    globalS=\"Global South\",\n",
    "    globalN=\"Global North\",\n",
    "    globalN_domestic_NAEU=\"Domestic N.A./Europe\",\n",
    ")\n",
    "table_years = [2020, 2040, 2060]\n",
    "table_scenarios = dict(IntLow=\"Int. Low\", Int=\"Intermediate\", IntHigh=\"Int. High\")\n",
    "table_columns = [c for c in product([s for s in table_scenarios], table_years)]\n",
    "table_quantities = [f\"dt_median_26_days_{c[0]}_{c[1]}\" for c in table_columns]\n",
    "\n",
    "\n",
    "table_dt = group_percentiles.loc[[g for g in table_groups], table_quantities]\n",
    "table_dt = table_dt.map(lambda x: x[2] if len(x) > 2 else None).round().astype(int)\n",
    "table_dt.columns = table_columns\n",
    "\n",
    "fig = dt_table(table_dt, table_groups, table_scenarios)\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dt_table.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dt_table.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3ebcf-e630-4d40-b9b6-e95c86fb7363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Scatter maps of $\\Delta h$ and $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d0ddd-5bf4-49f9-a9ed-00106d25e59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# make the figure and subplots\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "    3,\n",
    "    1,\n",
    "    figsize=(8, 10),\n",
    "    subplot_kw=dict(projection=ccrs.Mollweide(central_longitude=210)),\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# delta h\n",
    "\n",
    "c_sorted = analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"].sort_values(\n",
    "    ascending=True\n",
    ")\n",
    "o2c_scatter_map(\n",
    "    fig=fig,\n",
    "    ax=ax1,\n",
    "    x=analysis.lon.loc[c_sorted.index],\n",
    "    y=analysis.lat.loc[c_sorted.index],\n",
    "    c=c_sorted,\n",
    "    squares=analysis.hdi.loc[c_sorted.index] < 0.8,\n",
    "    vmin=5,\n",
    "    vmax=30,\n",
    "    alpha=1,\n",
    "    splab=\"a\",\n",
    "    title=\"∆h\",\n",
    "    cbar_label=\"cm\",\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# delta t beginning 2020\n",
    "\n",
    "c_sorted = analysis[\n",
    "    f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"\n",
    "].sort_values(ascending=True)\n",
    "o2c_scatter_map(\n",
    "    fig=fig,\n",
    "    ax=ax2,\n",
    "    x=analysis.lon.loc[c_sorted.index],\n",
    "    y=analysis.lat.loc[c_sorted.index],\n",
    "    c=c_sorted,\n",
    "    squares=analysis.hdi.loc[c_sorted.index] < 0.8,\n",
    "    vmin=5,\n",
    "    vmax=50,\n",
    "    alpha=1,\n",
    "    splab=\"b\",\n",
    "    title=\"∆t beginning in 2020\",\n",
    "    cbar_label=\"years\",\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Delta t beginning 2050\n",
    "\n",
    "c_sorted = analysis[\n",
    "    f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2050\"\n",
    "].sort_values(ascending=True)\n",
    "o2c_scatter_map(\n",
    "    fig=fig,\n",
    "    ax=ax3,\n",
    "    x=analysis.lon.loc[c_sorted.index],\n",
    "    y=analysis.lat.loc[c_sorted.index],\n",
    "    c=c_sorted,\n",
    "    squares=analysis.hdi.loc[c_sorted.index] < 0.8,\n",
    "    vmin=5,\n",
    "    vmax=50,\n",
    "    alpha=1,\n",
    "    splab=\"c\",\n",
    "    title=\"∆t beginning in 2050\",\n",
    "    cbar_label=\"years\",\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# fig.savefig(\"./figures/manuscript/dh_dt_scatter_maps.png\", dpi=300)\n",
    "# fig.savefig(\"./figures/manuscript/dh_dt_scatter_maps.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc672cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# make the figure and subplots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 7),\n",
    "    subplot_kw=dict(projection=ccrs.Mollweide(central_longitude=210)),\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# delta h\n",
    "\n",
    "c_sorted = analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"].sort_values(\n",
    "    ascending=True\n",
    ")\n",
    "o2c_scatter_map(\n",
    "    fig=fig,\n",
    "    ax=ax1,\n",
    "    x=analysis.lon.loc[c_sorted.index],\n",
    "    y=analysis.lat.loc[c_sorted.index],\n",
    "    c=c_sorted,\n",
    "    squares=analysis.hdi.loc[c_sorted.index] < 0.8,\n",
    "    vmin=5,\n",
    "    vmax=30,\n",
    "    alpha=1,\n",
    "    splab=\"a\",\n",
    "    title=\"∆h\",\n",
    "    cbar_label=\"cm\",\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# delta t beginning 2020\n",
    "\n",
    "c_sorted = analysis[\n",
    "    f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"\n",
    "].sort_values(ascending=True)\n",
    "o2c_scatter_map(\n",
    "    fig=fig,\n",
    "    ax=ax2,\n",
    "    x=analysis.lon.loc[c_sorted.index],\n",
    "    y=analysis.lat.loc[c_sorted.index],\n",
    "    c=c_sorted,\n",
    "    squares=analysis.hdi.loc[c_sorted.index] < 0.8,\n",
    "    vmin=5,\n",
    "    vmax=50,\n",
    "    alpha=1,\n",
    "    splab=\"b\",\n",
    "    title=\"∆t\",\n",
    "    cbar_label=\"years\",\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "leglab = [\"Global South\", \"Global North\"]\n",
    "# make dummy square and circle plots for the legend\n",
    "att = dict(c=\"lightgray\", ls=\"none\", lw=0.5, ms=8, mec=\"k\", mew=0.5)\n",
    "l1 = ax1.plot(0, 1e7, marker=\"s\", label=leglab[0], **att)[0]\n",
    "l2 = ax1.plot(0, 1e7, marker=\"o\", label=leglab[1], **att)[0]\n",
    "fig.legend(\n",
    "    [l1, l2],\n",
    "    leglab,\n",
    "    ncols=1,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.73, 0.485),\n",
    "    frameon=False,\n",
    "    labelspacing=0.5,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_scatter_maps.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_scatter_maps.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e90b3-fbc3-4c36-b982-2479e1529865",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Scatter plots of $\\Delta h$ and $\\Delta t$ vs. various predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, ax = plt.subplots(2, 4, figsize=(8.5, 4.5))\n",
    "ax = ax.flatten()\n",
    "\n",
    "group_highlight = groups[\"globalS\"]\n",
    "marker_size = 30\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# subplot data\n",
    "ymax_top = 46\n",
    "ymax_bottom = 85\n",
    "subplots = [\n",
    "    # a\n",
    "    dict(\n",
    "        x=analysis.res_hf_dymx_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=None,\n",
    "        y=analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"],\n",
    "        ylim=[0, ymax_top],\n",
    "        ylab=r\"$\\Delta h$ (cm)\",\n",
    "    ),\n",
    "    # b\n",
    "    dict(\n",
    "        x=analysis.res_momn_q75_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=None,\n",
    "        y=analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"],\n",
    "        ylim=[0, ymax_top],\n",
    "    ),\n",
    "    # c\n",
    "    dict(\n",
    "        x=analysis.tide_dymx_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=None,\n",
    "        y=analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"],\n",
    "        ylim=[0, ymax_top],\n",
    "    ),\n",
    "    None,\n",
    "    # d\n",
    "    dict(\n",
    "        x=analysis.res_hf_dymx_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=\"Storminess (cm)\",\n",
    "        # xlab=r\"$\\sigma\\,$: daily max $\\eta'_{hf}$ (cm)\",\n",
    "        y=analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"],\n",
    "        ylim=[0, ymax_bottom],\n",
    "        ylab=r\"$\\Delta t$ (years)\",  # _{\\mathrm{20}}$ (years)\",\n",
    "        # title=\"Storminess\",\n",
    "    ),\n",
    "    # e\n",
    "    dict(\n",
    "        x=analysis.res_momn_q75_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=\"MSL variability (cm)\",\n",
    "        # xlab=r\"$\\sigma\\,$: $\\eta'_{lf}$ (cm)\",\n",
    "        y=analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"],\n",
    "        ylim=[0, ymax_bottom],\n",
    "        # title=\"Monthly MSL variability\",\n",
    "    ),\n",
    "    # f\n",
    "    dict(\n",
    "        x=analysis.tide_dymx_std,\n",
    "        xlim=[0, 19],\n",
    "        xlab=\"High-tide modulation (cm)\",\n",
    "        # xlab=r\"$\\sigma\\,$: daily max $\\zeta$ (cm)\",\n",
    "        y=analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"],\n",
    "        ylim=[0, ymax_bottom],\n",
    "        # title=\"High-tide modulation\",\n",
    "    ),\n",
    "    # f\n",
    "    dict(\n",
    "        x=analysis[f\"slr_total_{scenario}_2020_2050\"],\n",
    "        xlim=[0, 40],\n",
    "        xlab=\"Sea-level rise (cm)\",  # \"Int. SLR 2020–50 (cm)\",\n",
    "        # xlab=r\"$\\sigma\\,$: daily max $\\zeta$ (cm)\",\n",
    "        y=analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"],\n",
    "        ylim=[0, ymax_bottom],\n",
    "        # title=\"High-tide modulation\",\n",
    "        r_loc=(0.96, 0.89),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "[a.remove() for a, sp in zip(ax, subplots) if sp is None]\n",
    "subplots = [(a, sp) for a, sp in zip(ax, subplots) if sp is not None]\n",
    "for k, (a, sp) in enumerate(subplots):\n",
    "    o2c_scatter_plot(\n",
    "        ax=a,\n",
    "        x=sp[\"x\"],\n",
    "        y=sp[\"y\"],\n",
    "        ghl=group_highlight,\n",
    "        col=[colors[n] for n in [0, 1]],\n",
    "        ms=marker_size,\n",
    "        title=sp[\"title\"] if \"title\" in sp else None,\n",
    "        splab=chr(97 + k),\n",
    "        r_loc=sp[\"r_loc\"] if \"r_loc\" in sp else None,\n",
    "        xlim=sp[\"xlim\"] if \"xlim\" in sp else None,\n",
    "        xlab=sp[\"xlab\"],\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        ylab=sp[\"ylab\"] if \"ylab\" in sp else None,\n",
    "    )\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# spacing trick to add space above top row of figures\n",
    "# ax[0].annotate(\n",
    "#     text=r\"$~$\",\n",
    "#     xy=(0.5, 1.15),\n",
    "#     xycoords=\"axes fraction\",\n",
    "# )\n",
    "\n",
    "leglab = [\"Global South\", \"Global North\"]\n",
    "fig.legend(\n",
    "    leglab,\n",
    "    ncols=1,\n",
    "    loc=\"upper right\",\n",
    "    bbox_to_anchor=(0.95, 0.87),\n",
    "    frameon=False,\n",
    "    labelspacing=0.5,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_sigma_scatter_plots.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_sigma_scatter_plots.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e2164",
   "metadata": {},
   "source": [
    "#### Correlations between predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations between the predictors\n",
    "scn = scenario\n",
    "# scn = \"High\"\n",
    "quantities = [\n",
    "    analysis[f\"dh_{central_est_type}_{chronic_freq}_days\"],\n",
    "    analysis[f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\"],\n",
    "    analysis.res_hf_dymx_std,\n",
    "    analysis.res_momn_q75_std,\n",
    "    analysis.tide_dymx_std,\n",
    "    analysis[f\"slr_total_{scn}_2020_2050\"],\n",
    "    analysis[f\"slr_massdef_{scn}_2020_2050\"],\n",
    "    analysis[f\"slr_ocean_dyn_{scn}_2020_2050\"],\n",
    "    analysis[f\"slr_vlm_{scn}_2020_2050\"],\n",
    "]\n",
    "names = [\n",
    "    \"dh\",\n",
    "    \"dt\",\n",
    "    \"Storminess\",\n",
    "    \"MSL variability\",\n",
    "    \"High-tide modulation\",\n",
    "    \"Sea-level rise\",\n",
    "    \"Mass/Deformation\",\n",
    "    \"Sterodynamic\",\n",
    "    \"Land motion\",\n",
    "]\n",
    "rmat = pd.DataFrame(np.corrcoef(quantities, rowvar=True), index=names, columns=names)\n",
    "z = np.isfinite(quantities[1])\n",
    "r_dt = [np.corrcoef(quantities[1][z], q[z])[0, 1] for q in quantities]\n",
    "rmat.loc[\"dt\"] = r_dt\n",
    "rmat[\"dt\"] = r_dt\n",
    "rmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93eea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine significance of correlations based on t-test\n",
    "dof = 14  # degrees of freedom\n",
    "tmat = rmat / np.sqrt((1 - rmat**2) / (dof))  # t-statistic\n",
    "pvals = 2 * t.sf(np.abs(tmat), dof)\n",
    "pvalmat = np.zeros_like(pvals).astype(str)\n",
    "for m in range(len(names)):\n",
    "    for n in range(len(names)):\n",
    "        if m == n:\n",
    "            pvalmat[m, n] = \"-\"\n",
    "        elif pvals[m, n] <= 0.01:  # highly significant\n",
    "            pvalmat[m, n] = f\"**{pvals[m, n]:.3f}\"\n",
    "        elif pvals[m, n] <= 0.05:  # significant\n",
    "            pvalmat[m, n] = f\"*{pvals[m, n]:.3f}\"\n",
    "        else:\n",
    "            pvalmat[m, n] = f\"{pvals[m, n]:.3f}\"\n",
    "pvalmat = pd.DataFrame(pvalmat, index=names, columns=names)\n",
    "pvalmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d42427",
   "metadata": {},
   "source": [
    "#### Partial correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_correlation(x, y, Z):\n",
    "    x = analysis[x].values  # variable 1\n",
    "    y = analysis[y].values  # variable 2\n",
    "    Z = analysis[Z].values  # confounding variables\n",
    "    Z = np.hstack([Z, np.ones((Z.shape[0], 1))])\n",
    "    kp = np.isfinite(x) & np.isfinite(y) & np.isfinite(Z).sum(axis=1).astype(bool)\n",
    "    cy = np.linalg.lstsq(Z[kp, :], y[kp], rcond=None)[0]\n",
    "    yp = (Z @ cy).flatten()\n",
    "    cx = np.linalg.lstsq(Z[kp, :], x[kp], rcond=None)[0]\n",
    "    xp = (Z @ cx).flatten()\n",
    "    pc = np.corrcoef((y - yp)[kp], (x - xp)[kp])[0, 1]\n",
    "    return pc\n",
    "\n",
    "\n",
    "# partial correlations with dh controlling for a single confounding variable\n",
    "prx = {\n",
    "    \"storminess\": \"res_hf_dymx_std\",\n",
    "    \"MSL variability\": \"res_momn_q75_std\",\n",
    "    \"high-tide modulation\": \"tide_dymx_std\",\n",
    "}\n",
    "for c in prx:\n",
    "    for v in [p for p in prx if p != c]:\n",
    "        pc = partial_correlation(\n",
    "            x=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "            y=prx[v],\n",
    "            Z=[prx[c]],\n",
    "        )\n",
    "        print(f\"Partial correlation between dh and {v} controlling for {c}: {pc:.3f}\")\n",
    "v = \"storminess\"\n",
    "c = [p for p in prx if p != v]\n",
    "pc = partial_correlation(\n",
    "    x=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "    y=prx[v],\n",
    "    Z=[prx[cn] for cn in c],\n",
    ")\n",
    "print(\n",
    "    f\"Partial correlation between dh and {v} controlling for {' and '.join(c)}: {pc:.3f}\"\n",
    ")\n",
    "\n",
    "# # partial correlations with dt controlling for storminess and SLR\n",
    "# scn = \"Int\"\n",
    "# t0 = 2020\n",
    "# pc = partial_correlation(\n",
    "#     x=f\"slr_total_{scn}_{t0}_{t0+30}\",\n",
    "#     y=f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\",\n",
    "#     z=[\"res_hf_dymx_std\"],\n",
    "# )\n",
    "# print(f\"Partial correlation between dt and SLR controlling for storminess: {pc:.3f}\")\n",
    "# pc = partial_correlation(\n",
    "#     x=\"res_hf_dymx_std\",\n",
    "#     y=f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\",\n",
    "#     z=f\"slr_total_{scn}_{t0}_{t0+30}\",\n",
    "# )\n",
    "# print(f\"Partial correlation between dt and storminess controlling for SLR: {pc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0a05b",
   "metadata": {},
   "source": [
    "#### Variance explained in regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b16c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression(y, factors):\n",
    "    X = analysis[factors].values\n",
    "    X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    y = analysis[y].values\n",
    "    z = np.isfinite(y)\n",
    "    X = X[z, :]\n",
    "    y = y[z]\n",
    "    c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    yp = X @ c\n",
    "    r2 = 1 - np.sum((y - yp) ** 2) / np.sum((y - np.mean(y)) ** 2)\n",
    "    return c, r2\n",
    "\n",
    "\n",
    "# multiple regression of delta h onto the storminess proxy alone\n",
    "c, r2 = multiple_regression(\n",
    "    y=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "    factors=[\"res_hf_dymx_std\"],\n",
    ")\n",
    "print(f\"Variance in dh explained by the regression onto storminess proxy: {r2:.2f}\")\n",
    "\n",
    "# multiple linear regression of the proxies on delta h\n",
    "c, r2 = multiple_regression(\n",
    "    y=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "    factors=[\"res_hf_dymx_std\", \"res_momn_q75_std\", \"tide_dymx_std\"],\n",
    ")\n",
    "print(f\"Variance in dh explained by the regression onto all proxies: {r2:.2f}\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "for scn in [\"IntLow\", \"Int\", \"High\"]:\n",
    "    for t0 in [2020, 2050]:\n",
    "\n",
    "        # 17th, 50th, and 83rd percentiles of dt values\n",
    "        dt_percentiles = analysis[\n",
    "            f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\"\n",
    "        ].quantile([0.17, 0.5, 0.83])\n",
    "        print(\n",
    "            f\"17th, 50th, and 83rd percentiles of dt ({scn}, {t0}): {dt_percentiles.values}\"\n",
    "        )\n",
    "\n",
    "        # multiple regression of delta t onto the storminess proxy alone\n",
    "        c, r2 = multiple_regression(\n",
    "            y=f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\",\n",
    "            factors=[\"res_hf_dymx_std\"],\n",
    "        )\n",
    "        print(\n",
    "            f\"Variance in dt ({scn}, {t0}) explained by the regression onto storminess proxy: {r2:.2f}\"\n",
    "        )\n",
    "\n",
    "        # multiple regression of delta t onto SLR\n",
    "        c, r2 = multiple_regression(\n",
    "            y=f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\",\n",
    "            factors=[f\"slr_total_{scn}_{t0}_{t0+30}\"],\n",
    "        )\n",
    "        print(\n",
    "            f\"Variance in dt ({scn}, {t0}) explained by the regression onto SLR: {r2:.2f}\"\n",
    "        )\n",
    "\n",
    "        # multiple regression of  delta t onto the storminess proxy and SLR\n",
    "        c, r2 = multiple_regression(\n",
    "            y=f\"dt_{central_est_type}_{chronic_freq}_days_{scn}_{t0}\",\n",
    "            factors=[\"res_hf_dymx_std\", f\"slr_total_{scn}_{t0}_{t0+30}\"],\n",
    "        )\n",
    "        print(\n",
    "            f\"Variance in dt ({scn}, {t0}) explained by the regression onto storminess and SLR: {r2:.2f}\"\n",
    "        )\n",
    "        print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3b359-84e9-45ef-a1b5-8b41be2bb1b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Histogram violins: Global binary classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_groups = [\n",
    "    \"lowLat\",\n",
    "    \"highLat\",\n",
    "    # \"highLat_eastHemi\",\n",
    "    # \"highLat_westHemi\",\n",
    "    \"island\",\n",
    "    \"continent\",\n",
    "    \"globalS\",\n",
    "    \"globalN\",\n",
    "    # \"globalS_island\",\n",
    "    # \"not_globalS_island\",\n",
    "    # \"globalS_lowLat_island\",\n",
    "    # \"lucky\",\n",
    "]\n",
    "violin_group_names = [\n",
    "    \"Low Latitude\",\n",
    "    \"High Latitude\",\n",
    "    # \"E.H. High Lat.\",\n",
    "    # \"W.H. High Lat.\",\n",
    "    \"Islands\",\n",
    "    \"Continents\",\n",
    "    \"Global South\",\n",
    "    \"Global North\",\n",
    "    # \"LLGS Islands\",\n",
    "    # \"HLGN Continents\",\n",
    "]\n",
    "\n",
    "subplots = [\n",
    "    dict(\n",
    "        var=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=35,\n",
    "        ylim=[0, 35],\n",
    "        yticks=[0, 10, 20, 30],\n",
    "        wfact=3.4,\n",
    "        ylab=r\"$\\Delta h$ (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    dict(\n",
    "        var=f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=25,\n",
    "        ylim=[0, 70],\n",
    "        yticks=[0, 20, 40, 60],\n",
    "        wfact=6,\n",
    "        ylab=r\"$\\Delta t$ (years)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"res_hf_dymx_std\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=30,\n",
    "        ylim=[0, 17.5],\n",
    "        yticks=[0, 5, 10, 15],\n",
    "        wfact=1.2,\n",
    "        ylab=r\"Storminess (cm)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_total_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=1.85,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[8, 27],\n",
    "        yticks=[10, 15, 20, 25],\n",
    "        ylab=r\"Total relative SLR (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    # dict(\n",
    "    #     var=\"res_momn_std\",\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     nbins=15,\n",
    "    #     ylim=[0, 17.5],\n",
    "    #     yticks=[0, 5, 10, 15],\n",
    "    #     wfact=1.15,\n",
    "    #     ylab=r\"Monthly MSL variability (cm)\",\n",
    "    # ),\n",
    "    # dict(\n",
    "    #     var=\"tide_dymx_std\",\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     nbins=25,\n",
    "    #     ylim=[0, 17.5],\n",
    "    #     yticks=[0, 5, 10, 15],\n",
    "    #     wfact=1.75,\n",
    "    #     ylab=r\"Tidal modulation (cm)\",\n",
    "    # ),\n",
    "]\n",
    "\n",
    "for sp in subplots:\n",
    "    quantities = dict(\n",
    "        samples={g: analysis[sp[\"var\"]].loc[groups[g]].values for g in violin_groups},\n",
    "        median=analysis[sp[\"var\"]].median(),\n",
    "        diff_sig=io_median_diff_percentiles.loc[sp[\"var\"], significance_level],\n",
    "    )\n",
    "    sp.update(quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4262df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8.5, 6), sharex=True)\n",
    "axes = axes.flatten()\n",
    "[sp.update(dict(axis=axes[n])) for n, sp in enumerate(subplots)]\n",
    "[ax.remove() for ax in axes[len(subplots) :]]\n",
    "\n",
    "# set horizontal spacing of violin histograms\n",
    "violin_locs = [0, 1, 3, 4, 6, 7]\n",
    "\n",
    "Nvg = len(violin_groups)\n",
    "for k, sp in enumerate(subplots):\n",
    "    ax = sp[\"axis\"]\n",
    "    hist_violin(\n",
    "        ax=ax,\n",
    "        samples=sp[\"samples\"],\n",
    "        median=sp[\"median\"],\n",
    "        ylab=sp[\"ylab\"],\n",
    "        group_names=violin_group_names,\n",
    "        sp_letter=chr(97 + k),\n",
    "        width_factor=sp[\"wfact\"],\n",
    "        mnmx_pctls=sp[\"mnmx_pctls\"],\n",
    "        n_bins=sp[\"nbins\"],\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        yticks=sp[\"yticks\"] if \"yticks\" in sp else None,\n",
    "        violin_locs=violin_locs,\n",
    "        diff_sig=sp[\"diff_sig\"],\n",
    "        leglab=sp[\"leglab\"] if \"leglab\" in sp else None,\n",
    "        colors=colors,\n",
    "    )\n",
    "\n",
    "# spacing trick to add space above top row of figures\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.25),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leg_init = fig.legend()\n",
    "ordered_leg_handles = [leg_init.legend_handles[k] for k in [3, 0, 1, 2]]\n",
    "ordered_leg_labels = [h.get_label() for h in ordered_leg_handles]\n",
    "ordered_leg_handles[1] = MulticolorPatch([colors[0], colors[3]])\n",
    "leg_init.remove()\n",
    "leg = fig.legend(\n",
    "    handles=ordered_leg_handles,\n",
    "    labels=ordered_leg_labels,\n",
    "    ncols=2,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.53, 0.98),\n",
    "    frameon=False,\n",
    "    handler_map={MulticolorPatch: MulticolorPatchHandler()},\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_group_comparisons.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_group_comparisons.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a06ea",
   "metadata": {},
   "source": [
    "### Histogram violins: Socioeconomic classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_groups = [\n",
    "    \"globalS\",\n",
    "    \"globalN_domestic\",\n",
    "    \"globalS\",\n",
    "    \"globalN_domestic_westHemi\",\n",
    "    \"globalS\",\n",
    "    \"globalN_domestic_NAEU\",\n",
    "]\n",
    "violin_group_names = [\n",
    "    \"Global South\",\n",
    "    \"Domestic G. North\",\n",
    "    \"Global South\",\n",
    "    \"W.H. Dom. G. North\",\n",
    "    \"Global South\",\n",
    "    \"Domestic N.A./Europe\",\n",
    "]\n",
    "\n",
    "subplots = [\n",
    "    dict(\n",
    "        var=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=35,\n",
    "        ylim=[0, 35],\n",
    "        yticks=[0, 10, 20, 30],\n",
    "        wfact=3.4,\n",
    "        ylab=r\"$\\Delta h$ (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    # dict(\n",
    "    #     var=f\"hdi\",\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     nbins=15,\n",
    "    #     ylim=[0.55, 1.05],\n",
    "    #     yticks=[0.6, 0.8, 1.0],\n",
    "    #     wfact=0.05,\n",
    "    #     ylab=r\"HDI\",\n",
    "    #     leglab=True,\n",
    "    # ),\n",
    "    dict(\n",
    "        var=f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=25,\n",
    "        ylim=[0, 70],\n",
    "        yticks=[0, 20, 40, 60],\n",
    "        wfact=6,\n",
    "        ylab=r\"$\\Delta t$ (years)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"res_hf_dymx_std\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=30,\n",
    "        ylim=[0, 17.5],\n",
    "        yticks=[0, 5, 10, 15],\n",
    "        wfact=1.2,\n",
    "        ylab=r\"Storminess (cm)\",\n",
    "    ),\n",
    "    # dict(\n",
    "    #     var=\"slr_total_Int_2020_2050\",\n",
    "    #     nbins=40,\n",
    "    #     wfact=1.85,\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     ylim=[8, 27],\n",
    "    #     yticks=[10, 15, 20, 25],\n",
    "    #     ylab=r\"Sea-level rise (cm)\",\n",
    "    #     leglab=True,\n",
    "    # ),\n",
    "    dict(\n",
    "        var=\"slr_massdef_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=0.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[4, 12],\n",
    "        yticks=[5, 7, 9, 11],\n",
    "        ylab=r\"Mass and deformation (cm)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for sp in subplots:\n",
    "    quantities = dict(\n",
    "        samples={g: analysis[sp[\"var\"]].loc[groups[g]].values for g in violin_groups},\n",
    "        median=analysis[sp[\"var\"]].median(),\n",
    "        diff_sig=io_exclusion_median_diff_percentiles.loc[\n",
    "            sp[\"var\"], significance_level\n",
    "        ],\n",
    "    )\n",
    "    sp.update(quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6882cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6.5), sharex=True)\n",
    "axes = axes.flatten()\n",
    "[sp.update(dict(axis=axes[n])) for n, sp in enumerate(subplots)]\n",
    "[ax.remove() for ax in axes[len(subplots) :]]\n",
    "\n",
    "# set horizontal spacing of violin histograms\n",
    "violin_locs = [0, 1, 3, 4, 6, 7]\n",
    "\n",
    "Nvg = len(violin_groups)\n",
    "for k, sp in enumerate(subplots):\n",
    "    ax = sp[\"axis\"]\n",
    "    hist_violin(\n",
    "        ax=ax,\n",
    "        samples=sp[\"samples\"],\n",
    "        sample_names=violin_groups,\n",
    "        median=sp[\"median\"],\n",
    "        ylab=sp[\"ylab\"],\n",
    "        group_names=violin_group_names,\n",
    "        sp_letter=chr(97 + k),\n",
    "        width_factor=sp[\"wfact\"],\n",
    "        mnmx_pctls=sp[\"mnmx_pctls\"],\n",
    "        n_bins=sp[\"nbins\"],\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        yticks=sp[\"yticks\"] if \"yticks\" in sp else None,\n",
    "        violin_locs=violin_locs,\n",
    "        diff_sig=sp[\"diff_sig\"],\n",
    "        leglab=sp[\"leglab\"] if \"leglab\" in sp else None,\n",
    "        colors=colors,\n",
    "    )\n",
    "\n",
    "# spacing trick to add space above top row of figures\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.25),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leg_init = fig.legend()\n",
    "ordered_leg_handles = [leg_init.legend_handles[k] for k in [3, 0, 1, 2]]\n",
    "ordered_leg_labels = [h.get_label() for h in ordered_leg_handles]\n",
    "ordered_leg_handles[1] = MulticolorPatch([colors[0], colors[3]])\n",
    "leg_init.remove()\n",
    "leg = fig.legend(\n",
    "    handles=ordered_leg_handles,\n",
    "    labels=ordered_leg_labels,\n",
    "    ncols=2,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.53, 0.98),\n",
    "    frameon=False,\n",
    "    handler_map={MulticolorPatch: MulticolorPatchHandler()},\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_socioecon_comparisons.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_socioecon_comparisons.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3266c",
   "metadata": {},
   "source": [
    "### Histogram violins: Contributions to SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_groups = [\n",
    "    \"lowLat\",\n",
    "    \"highLat\",\n",
    "    \"highLat_eastHemi\",\n",
    "    \"highLat_westHemi\",\n",
    "    \"lowLat_eastHemi\",\n",
    "    \"lowLat_westHemi\",\n",
    "    # \"island\",\n",
    "    # \"continent\",\n",
    "    # \"globalS\",\n",
    "    # \"globalN\",\n",
    "    # \"globalS_island\",\n",
    "    # \"not_globalS_island\",\n",
    "    # \"globalS_lowLat_island\",\n",
    "    # \"lucky\",\n",
    "]\n",
    "violin_group_names = [\n",
    "    \"Low Latitude\",\n",
    "    \"High Latitude\",\n",
    "    \"E.H. High Lat.\",\n",
    "    \"W.H. High Lat.\",\n",
    "    \"E.H. Low Lat.\",\n",
    "    \"W.H. Low Lat.\",\n",
    "    # \"Islands\",\n",
    "    # \"Continents\",\n",
    "    # \"Global South\",\n",
    "    # \"Global North\",\n",
    "    # \"LLGS Islands\",\n",
    "    # \"HLGN Continents\",\n",
    "]\n",
    "\n",
    "subplots = [\n",
    "    dict(\n",
    "        var=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=35,\n",
    "        ylim=[0, 35],\n",
    "        yticks=[0, 10, 20, 30],\n",
    "        wfact=3.4,\n",
    "        ylab=r\"$\\Delta h$ (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    dict(\n",
    "        var=f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=25,\n",
    "        ylim=[0, 70],\n",
    "        yticks=[0, 20, 40, 60],\n",
    "        wfact=6,\n",
    "        ylab=r\"$\\Delta t$ (years)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_total_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=1.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[8, 27],\n",
    "        yticks=[10, 15, 20, 25],\n",
    "        ylab=r\"Total relative SLR (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_massdef_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=0.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[4, 12],\n",
    "        yticks=[5, 7, 9, 11],\n",
    "        ylab=r\"Mass and deformation (cm)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for sp in subplots:\n",
    "    quantities = dict(\n",
    "        samples={g: analysis[sp[\"var\"]].loc[groups[g]].values for g in violin_groups},\n",
    "        median=analysis[sp[\"var\"]].median(),\n",
    "        diff_sig=io_median_diff_percentiles.loc[sp[\"var\"], significance_level],\n",
    "    )\n",
    "    sp.update(quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ce3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6), sharex=True)\n",
    "axes = axes.flatten()\n",
    "[sp.update(dict(axis=axes[n])) for n, sp in enumerate(subplots)]\n",
    "\n",
    "violin_locs = [0, 1, 3, 4, 6, 7]\n",
    "\n",
    "Nvg = len(violin_groups)\n",
    "for k, sp in enumerate(subplots):\n",
    "    ax = sp[\"axis\"]\n",
    "    hist_violin(\n",
    "        ax=ax,\n",
    "        samples=sp[\"samples\"],\n",
    "        median=sp[\"median\"],\n",
    "        ylab=sp[\"ylab\"],\n",
    "        group_names=violin_group_names,\n",
    "        sp_letter=chr(97 + k),\n",
    "        width_factor=sp[\"wfact\"],\n",
    "        n_bins=sp[\"nbins\"],\n",
    "        mnmx_pctls=sp[\"mnmx_pctls\"],\n",
    "        violin_locs=violin_locs,\n",
    "        diff_sig=sp[\"diff_sig\"],\n",
    "        leglab=sp[\"leglab\"] if \"leglab\" in sp else None,\n",
    "        colors=colors,\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        yticks=sp[\"yticks\"] if \"yticks\" in sp else None,\n",
    "    )\n",
    "\n",
    "# spacing trick to add space above top row of figures\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.25),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leg_init = fig.legend()\n",
    "ordered_leg_handles = [leg_init.legend_handles[k] for k in [3, 0, 1, 2]]\n",
    "ordered_leg_labels = [h.get_label() for h in ordered_leg_handles]\n",
    "ordered_leg_handles[1] = MulticolorPatch([colors[0], colors[3]])\n",
    "leg_init.remove()\n",
    "leg = fig.legend(\n",
    "    handles=ordered_leg_handles,\n",
    "    labels=ordered_leg_labels,\n",
    "    ncols=2,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.53, 0.98),\n",
    "    frameon=False,\n",
    "    handler_map={MulticolorPatch: MulticolorPatchHandler()},\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/slr_hemi_group_comparisons.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/slr_hemi_group_comparisons.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2926a1",
   "metadata": {},
   "source": [
    "### Histogram violins: Two socioeconomic groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {groups['globalS'].size} locations.\")\n",
    "\n",
    "Ngs_ex = np.sum(groups[\"globalS\"]) - np.sum(groups[\"globalS_island\"])\n",
    "print(\n",
    "    f\"{Ngs_ex} of {np.sum(groups['globalS'])} locations are excluded from the Global South when forming the GS Islands group.\"\n",
    ")\n",
    "Ngn_ex = np.sum(groups[\"globalN\"]) - np.sum(groups[\"globalN_continent\"])\n",
    "print(\n",
    "    f\"{Ngn_ex} of {np.sum(groups['globalN'])} locations are excluded from the Global North when forming the GN Continental group.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c81a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin_groups = [\n",
    "#     \"globalS_island\",\n",
    "#     \"globalN_continent\",\n",
    "# ]\n",
    "# violin_group_names = [\n",
    "#     \"GS Islands\",\n",
    "#     \"GN Continents\",\n",
    "# ]\n",
    "\n",
    "# violin_groups = [\n",
    "#     \"globalS\",\n",
    "#     \"globalN_westHemi_continent\",\n",
    "# ]\n",
    "# violin_group_names = [\n",
    "#     \"GS\",\n",
    "#     \"GN WH Continents\",\n",
    "# ]\n",
    "\n",
    "violin_groups = [\n",
    "    \"globalS\",\n",
    "    \"globalN_westHemi_highLat\",\n",
    "]\n",
    "violin_group_names = [\n",
    "    \"Global South\",\n",
    "    \"Global North, High-Latitude Western Hemisphere\",\n",
    "]\n",
    "\n",
    "subplots = [\n",
    "    dict(\n",
    "        var=f\"dh_{central_est_type}_{chronic_freq}_days\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=35,\n",
    "        ylim=[0, 35],\n",
    "        yticks=[0, 10, 20, 30],\n",
    "        wfact=3,\n",
    "        ylab=r\"$\\Delta h$ (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    dict(\n",
    "        var=f\"dt_{central_est_type}_{chronic_freq}_days_{scenario}_2020\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=25,\n",
    "        ylim=[0, 70],\n",
    "        yticks=[0, 20, 40, 60],\n",
    "        wfact=6,\n",
    "        ylab=r\"$\\Delta t$ (years)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"res_hf_dymx_std\",\n",
    "        mnmx_pctls=[0, 100],\n",
    "        nbins=30,\n",
    "        ylim=[0, 17.5],\n",
    "        yticks=[0, 5, 10, 15],\n",
    "        wfact=1.15,\n",
    "        ylab=r\"Storminess (cm)\",\n",
    "    ),\n",
    "    # dict(\n",
    "    #     var=\"slr_massdef_Int_2020_2050\",\n",
    "    #     nbins=40,\n",
    "    #     wfact=0.75,\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     ylim=[4, 12],\n",
    "    #     yticks=[5, 7, 9, 11],\n",
    "    #     ylab=r\"SLR: Mass and def. (cm)\",\n",
    "    # ),\n",
    "    dict(\n",
    "        var=\"slr_total_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=1.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[8, 27],\n",
    "        yticks=[10, 15, 20, 25],\n",
    "        ylab=r\"Sea-level rise (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    # dict(\n",
    "    #     var=\"slr_total_IntHigh_2050_2080\",\n",
    "    #     nbins=40,\n",
    "    #     wfact=1.75,\n",
    "    #     mnmx_pctls=[0, 100],\n",
    "    #     # ylim=[8, 27],\n",
    "    #     yticks=[10, 15, 20, 25],\n",
    "    #     ylab=r\"Sea-level rise (cm)\",\n",
    "    #     leglab=True,\n",
    "    # ),\n",
    "]\n",
    "\n",
    "for sp in subplots:\n",
    "    quantities = dict(\n",
    "        samples={g: analysis[sp[\"var\"]].loc[groups[g]].values for g in violin_groups},\n",
    "        median=analysis[sp[\"var\"]].median(),\n",
    "        diff_sig=io_exclusion_median_diff_percentiles.loc[\n",
    "            sp[\"var\"], significance_level\n",
    "        ],\n",
    "    )\n",
    "    sp.update(quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8.5, 3), sharex=True)\n",
    "axes = axes.flatten()\n",
    "[sp.update(dict(axis=axes[n])) for n, sp in enumerate(subplots)]\n",
    "\n",
    "violin_locs = [0, 1]\n",
    "\n",
    "Nvg = len(violin_groups)\n",
    "for k, sp in enumerate(subplots):\n",
    "    ax = sp[\"axis\"]\n",
    "    hist_violin(\n",
    "        ax=ax,\n",
    "        samples=sp[\"samples\"],\n",
    "        median=sp[\"median\"],\n",
    "        ylab=sp[\"ylab\"],\n",
    "        group_names=violin_group_names,\n",
    "        sp_letter=chr(97 + k),\n",
    "        sp_letter_loc=(0.08, 0.88),\n",
    "        width_factor=sp[\"wfact\"],\n",
    "        n_bins=sp[\"nbins\"],\n",
    "        mnmx_pctls=sp[\"mnmx_pctls\"],\n",
    "        violin_locs=violin_locs,\n",
    "        diff_sig=sp[\"diff_sig\"],\n",
    "        leglab=sp[\"leglab\"] if \"leglab\" in sp else None,\n",
    "        colors=colors,\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        yticks=sp[\"yticks\"] if \"yticks\" in sp else None,\n",
    "    )\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "# spacing trick to add space above/below figures\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.085),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, -0.14),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leg_init = fig.legend()\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[leg_init.legend_handles[k] for k in [0, 1]],\n",
    "    labels=violin_group_names,\n",
    "    ncols=2,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.525, 0.99),\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[leg_init.legend_handles[k] for k in [4, 2, 3]],\n",
    "    ncols=3,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.525, 0.01),\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "leg_init.remove()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_2grp_socio_comparisons.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/dh_dt_2grp_socio_comparisons.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c0bbc",
   "metadata": {},
   "source": [
    "### Histogram violins: Two groups SLR contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin_groups = [\n",
    "#     \"globalS_island\",\n",
    "#     \"globalN_continent\",\n",
    "# ]\n",
    "# violin_group_names = [\n",
    "#     \"GS Islands\",\n",
    "#     \"GN Continents\",\n",
    "# ]\n",
    "\n",
    "# violin_groups = [\n",
    "#     \"globalS\",\n",
    "#     \"globalN\",\n",
    "# ]\n",
    "# violin_group_names = [\n",
    "#     \"Global South\",\n",
    "#     \"Global North\",\n",
    "# ]\n",
    "\n",
    "violin_groups = [\n",
    "    \"globalS\",\n",
    "    \"globalN_westHemi_highLat\",\n",
    "]\n",
    "violin_group_names = [\n",
    "    \"Global South\",\n",
    "    \"Global North, High-Latitude Western Hemisphere\",\n",
    "]\n",
    "\n",
    "subplots = [\n",
    "    dict(\n",
    "        var=\"slr_total_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=1.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[8, 27],\n",
    "        yticks=[10, 15, 20, 25],\n",
    "        ylab=r\"Total relative SLR (cm)\",\n",
    "        leglab=True,\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_ocean_dyn_Int_2020_2050\",\n",
    "        nbins=20,\n",
    "        wfact=0.8,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[3, 13],\n",
    "        yticks=[4, 6, 8, 10, 12],\n",
    "        ylab=r\"Sterodynamic (cm)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_massdef_Int_2020_2050\",\n",
    "        nbins=40,\n",
    "        wfact=0.75,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[4, 12],\n",
    "        yticks=[5, 7, 9, 11],\n",
    "        ylab=r\"Mass and deformation (cm)\",\n",
    "    ),\n",
    "    dict(\n",
    "        var=\"slr_vlm_Int_2020_2050\",\n",
    "        nbins=70,\n",
    "        wfact=1.0,\n",
    "        mnmx_pctls=[0, 100],\n",
    "        ylim=[-5, 5],\n",
    "        ylab=r\"Vertical land motion (cm)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for sp in subplots:\n",
    "    quantities = dict(\n",
    "        samples={g: analysis[sp[\"var\"]].loc[groups[g]].values for g in violin_groups},\n",
    "        median=analysis[sp[\"var\"]].median(),\n",
    "        diff_sig=io_exclusion_median_diff_percentiles.loc[\n",
    "            sp[\"var\"], significance_level\n",
    "        ],\n",
    "    )\n",
    "    sp.update(quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1577f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8.5, 3), sharex=True)\n",
    "axes = axes.flatten()\n",
    "[sp.update(dict(axis=axes[n])) for n, sp in enumerate(subplots)]\n",
    "\n",
    "violin_locs = [0, 1]\n",
    "\n",
    "Nvg = len(violin_groups)\n",
    "for k, sp in enumerate(subplots):\n",
    "    ax = sp[\"axis\"]\n",
    "    hist_violin(\n",
    "        ax=ax,\n",
    "        samples=sp[\"samples\"],\n",
    "        median=sp[\"median\"],\n",
    "        ylab=sp[\"ylab\"],\n",
    "        group_names=violin_group_names,\n",
    "        sp_letter=chr(97 + k),\n",
    "        sp_letter_loc=(0.08, 0.88),\n",
    "        width_factor=sp[\"wfact\"],\n",
    "        n_bins=sp[\"nbins\"],\n",
    "        mnmx_pctls=sp[\"mnmx_pctls\"],\n",
    "        violin_locs=violin_locs,\n",
    "        diff_sig=sp[\"diff_sig\"],\n",
    "        leglab=sp[\"leglab\"] if \"leglab\" in sp else None,\n",
    "        colors=colors,\n",
    "        ylim=sp[\"ylim\"] if \"ylim\" in sp else None,\n",
    "        yticks=sp[\"yticks\"] if \"yticks\" in sp else None,\n",
    "    )\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "# spacing trick to add space above/below figures\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.085),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "axes[0].annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, -0.14),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leg_init = fig.legend()\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[leg_init.legend_handles[k] for k in [0, 1]],\n",
    "    labels=violin_group_names,\n",
    "    ncols=2,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.525, 0.99),\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[leg_init.legend_handles[k] for k in [4, 2, 3]],\n",
    "    ncols=3,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.525, 0.01),\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "leg_init.remove()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/slr_2grp_comparisons.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/slr_2grp_comparisons.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778cb3e",
   "metadata": {},
   "source": [
    "### Mass and deformation pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b55bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_prj = xr.open_dataset(\"./data/slr_scenarios/TR_gridded_projections.nc\")\n",
    "tot_slr = (\n",
    "    grd_prj[\"rsl_total_Int\"]\n",
    "    .sel(percentiles=50)\n",
    "    .sel(years=[2020, 2050])\n",
    "    .diff(dim=\"years\")\n",
    "    .isel(years=0)\n",
    ")\n",
    "tot_mass_def = (\n",
    "    xr.concat(\n",
    "        [\n",
    "            grd_prj[v].sel(percentiles=50)\n",
    "            for v in [\n",
    "                \"rsl_landwaterstorage_Int\",\n",
    "                \"rsl_AIS_Int\",\n",
    "                \"rsl_GIS_Int\",\n",
    "                \"rsl_glaciers_Int\",\n",
    "            ]\n",
    "        ],\n",
    "        dim=\"component\",\n",
    "    )\n",
    "    .sum(dim=\"component\")\n",
    "    .sel(years=[2020, 2050])\n",
    "    .diff(dim=\"years\")\n",
    "    .isel(years=0)\n",
    ")\n",
    "tot_mass_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    1,\n",
    "    1,\n",
    "    figsize=(8, 4),\n",
    "    subplot_kw=dict(projection=ccrs.Mollweide(central_longitude=210)),\n",
    ")\n",
    "\n",
    "\n",
    "def slr_map(ax, slr_map, slr_tg, minmax, title):\n",
    "    h = ax.imshow(\n",
    "        np.roll(slr_map.values / 10, 180, axis=1),  # cm\n",
    "        origin=\"lower\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=0,\n",
    "        vmin=minmax[0],\n",
    "        vmax=minmax[1],\n",
    "        cmap=\"plasma\",\n",
    "    )\n",
    "    ax.coastlines(zorder=15, lw=0.5)\n",
    "    for g, mrkr in zip([\"globalS\", \"globalN\"], [\"s\", \"o\"]):\n",
    "        ax.scatter(\n",
    "            x=analysis.lon.loc[groups[g]],\n",
    "            y=analysis.lat.loc[groups[g]],\n",
    "            s=30,\n",
    "            c=slr_tg.loc[groups[g]],\n",
    "            vmin=minmax[0],\n",
    "            vmax=minmax[1],\n",
    "            marker=mrkr,\n",
    "            lw=0.5,\n",
    "            edgecolor=\"k\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=\"plasma\",\n",
    "            zorder=20,\n",
    "        )\n",
    "        ax.scatter(\n",
    "            x=analysis.lon.loc[groups[g]],\n",
    "            y=analysis.lat.loc[groups[g]],\n",
    "            s=42,\n",
    "            c=\"w\",\n",
    "            marker=mrkr,\n",
    "            lw=0.5,\n",
    "            edgecolor=\"w\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            zorder=19,\n",
    "        )\n",
    "    ax.add_feature(cfeature.LAND.with_scale(\"110m\"), color=\"gray\", zorder=10)\n",
    "    ax.gridlines(linewidth=0.5, color=\"k\", linestyle=\":\")\n",
    "    axes.annotate(\n",
    "        text=title,\n",
    "        fontsize=11,\n",
    "        xy=(0.5, 1.11),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    axes.annotate(\n",
    "        text=r\"Intermediate Scenario, 2020-2050\",\n",
    "        fontsize=10,\n",
    "        # fontstyle=\"italic\",\n",
    "        xy=(0.5, 1.05),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    fig.colorbar(h, ax=ax, label=\"cm\", shrink=0.8, pad=0.02, extend=\"both\")\n",
    "\n",
    "\n",
    "slr_map_input = [\n",
    "    # dict(\n",
    "    #     ax=axes[0],\n",
    "    #     slr_map=tot_slr,\n",
    "    #     slr_tg=analysis.slr_total_Int_2020_2050,\n",
    "    #     minmax=[5, 21],\n",
    "    #     title=\"Total Relative SLR\",\n",
    "    # ),\n",
    "    dict(\n",
    "        ax=axes[1] if type(axes) is np.ndarray else axes,\n",
    "        slr_map=tot_mass_def,\n",
    "        slr_tg=analysis.slr_massdef_Int_2020_2050,\n",
    "        minmax=[0, 11],\n",
    "        title=\"SLR Contribution from Mass and Deformation\",\n",
    "    ),\n",
    "]\n",
    "for input in slr_map_input:\n",
    "    slr_map(\n",
    "        input[\"ax\"], input[\"slr_map\"], input[\"slr_tg\"], input[\"minmax\"], input[\"title\"]\n",
    "    )\n",
    "\n",
    "# spacing trick to add space above top row of figures\n",
    "axes.annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, 1.2),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "axes.annotate(\n",
    "    text=r\"$~$\",\n",
    "    xy=(0.5, -0.15),\n",
    "    xycoords=\"axes fraction\",\n",
    ")\n",
    "\n",
    "leglab = [\"Global South\", \"Global North\"]\n",
    "# make dummy square and circle plots for the legend\n",
    "att = dict(c=\"w\", ls=\"none\", lw=0.5, ms=7, mec=\"k\", mew=0.5)\n",
    "l1 = axes.plot(0, 1e7, marker=\"s\", label=leglab[0], **att)[0]\n",
    "l2 = axes.plot(0, 1e7, marker=\"o\", label=leglab[1], **att)[0]\n",
    "fig.legend(\n",
    "    [l1, l2],\n",
    "    leglab,\n",
    "    ncols=2,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.42, -0.02),\n",
    "    frameon=False,\n",
    "    labelspacing=0.5,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "fig.savefig(\"./figures/manuscript/massdef_map.png\", dpi=300)\n",
    "fig.savefig(\"./figures/manuscript/massdef_map.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
